{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "\n",
    "## Table of Contents\n",
    "1. [Model Choice](#model-choice)\n",
    "2. [Feature Selection](#feature-selection)\n",
    "3. [Implementation](#implementation)\n",
    "4. [Evaluation](#evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Choice\n",
    "\n",
    "**Logistic regression** was chosen as the baseline model for this machine learning task due to its simplicity, interpretability, and effectiveness in handling binary classification problems. As a linear model, it provides a strong foundation for understanding the relationship between features and the target variable.\n",
    "\n",
    "Moreover, given the presence of class imbalance in the dataset, a **cost-sensitive approach** was incorporated to address this issue. By assigning different weights to each class, the model is encouraged to focus on the minority class, thereby improving overall performance metrics.\n",
    "\n",
    "This combination of logistic regression and cost-sensitive learning offers a straightforward yet robust approach to tackle the classification problem while accounting for the imbalanced nature of the data. It serves as a solid baseline to compare the performance of more complex models.\n",
    "\n",
    "**Key reasons for choosing this baseline:**\n",
    "\n",
    "- **Simplicity:** Logistic regression is easy to implement and understand.\n",
    "- **Interpretability:** The model's coefficients can provide insights into feature importance.\n",
    "- **Efficiency:** Relatively fast training and prediction times.\n",
    "- **Handles imbalance:** The cost-sensitive approach directly addresses the class imbalance issue.\n",
    "\n",
    "By establishing a strong baseline, we can effectively evaluate the performance gains of more sophisticated models and make informed decisions about model selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "I am using all the features as we are using profiling of data and selecting features can impact the performace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Replace 'your_dataset.csv' with the path to your actual dataset\n",
    "df = pd.read_csv('clean_data.csv')\n",
    "\n",
    "# Feature selection\n",
    "X = df.drop('is_fraud', axis=1)\n",
    "y = df['is_fraud']\n",
    "\n",
    "X, y = shuffle(X, y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for each class {0: 0.5000945, 1: 2646.0026455026455}\n"
     ]
    }
   ],
   "source": [
    "#Assigning weights for cost sensitive learning\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y), y=y)\n",
    "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "print(\"Weights for each class\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(class_weight={0: 0.5000945,\n",
      "                                                  1: 2646.0026455026455},\n",
      "                                    max_iter=1000))])\n",
      "Best Parameters {'logisticregression__C': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the baseline model\n",
    "param_grid = {\n",
    "    \"logisticregression__C\": [0.01, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logisticregression', LogisticRegression(class_weight=class_weight_dict, max_iter=1000))\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, scoring='f1', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_model)\n",
    "print(\"Best Parameters\", best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "**F1 score** was used as the primary evaluation metric due to its effectiveness in handling imbalanced datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004407173899736793"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the baseline model\n",
    "#Using f1 score as evaluation metric\n",
    "predictions = best_model.predict(X_test)\n",
    "f1_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0      1\n",
      "0  183737  16260\n",
      "1       5     36\n",
      "              precision    recall  f1-score       support\n",
      "0              0.999973  0.918699  0.957614  199997.00000\n",
      "1              0.002209  0.878049  0.004407      41.00000\n",
      "accuracy       0.918690  0.918690  0.918690       0.91869\n",
      "macro avg      0.501091  0.898374  0.481011  200038.00000\n",
      "weighted avg   0.999768  0.918690  0.957419  200038.00000\n"
     ]
    }
   ],
   "source": [
    "# Create pandas DataFrame from confusion matrix\n",
    "cm_df = pd.DataFrame(cm, index=best_model.classes_, columns=best_model.classes_)\n",
    "\n",
    "# Print or display the confusion matrix DataFrame\n",
    "print(cm_df)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Print classification report in a more readable format (optional)\n",
    "print(pd.DataFrame(report).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
